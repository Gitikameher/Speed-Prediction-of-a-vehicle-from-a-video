{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os, random\n",
    "import matplotlib.pylab as plt\n",
    "import keras.utils.vis_utils as vutil\n",
    "from skimage.transform import resize\n",
    "from IPython.display import SVG\n",
    "import tensorflow as tf\n",
    "import keras.models as models\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import MaxPooling2D, UpSampling2D, Conv2D, Conv2DTranspose, ZeroPadding2D, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda, add, LSTM, TimeDistributed, concatenate\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.utils import conv_utils\n",
    "from keras.engine.topology import Layer\n",
    "from keras.engine import InputSpec\n",
    "import numpy as np\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.animation as animation\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_H, FRAME_W = 112, 112\n",
    "TIMESTEPS = 16\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "def show(image, cmap='gray', ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "    \n",
    "    plt.imshow(image[:,:,::-1].astype('uint8'), cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometime = lambda aug: iaa.Sometimes(0.3, aug)\n",
    "sequence = iaa.Sequential([ #sometime(iaa.GaussianBlur((0, 1.5))), # blur images with a sigma between 0 and 3.0\n",
    "                            #sometime(iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))), # sharpen images\n",
    "                            #sometime(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 3.), per_channel=0.5)), # add gaussian noise to images\n",
    "                            sometime(iaa.Dropout((0.0, 0.1))), # randomly remove up to 10% of the pixels\n",
    "                            sometime(iaa.CoarseDropout((0.0, 0.1), size_percent=(0.01, 0.02), per_channel=0.2)),\n",
    "                            #sometime(iaa.Add((-10, 10), per_channel=0.5)), # change brightness of images (by -10 to 10 of original value)\n",
    "                          ],\n",
    "                          random_order=True # do all of the above in random order\n",
    "                         )\n",
    "\n",
    "def normalize(image):\n",
    "    return image - [104.00699, 116.66877, 122.67892]\n",
    "\n",
    "def augment(image, flip, bright_factor):\n",
    "    # random disturbances borrowed from IAA\n",
    "    image = sequence.augment_image(image)\n",
    "    \n",
    "    # random brightness change\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    # random flip (vertical axis)\n",
    "    if flip:\n",
    "        image = cv2.flip(image, 1)\n",
    "                \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, file_path, indices, batch_size, timesteps=1, shuffle=True, jitter = True, norm=True, overlap=False):\n",
    "        self.file_path  = file_path\n",
    "        self.batch_size = batch_size\n",
    "        self.timesteps  = timesteps\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.jitter  = jitter\n",
    "        self.norm    = norm\n",
    "\n",
    "        self.images = sorted(os.listdir(self.file_path + 'images/'))\n",
    "        self.labels = open(self.file_path + 'labels.txt').readlines()\n",
    "        \n",
    "        self.indices = indices\n",
    "\n",
    "    def get_gen(self):\n",
    "        num_img = len(self.indices)\n",
    "        \n",
    "        l_bound = 0\n",
    "        r_bound = self.batch_size if self.batch_size < num_img else num_img    \n",
    "        \n",
    "        if self.shuffle: np.random.shuffle(self.indices)\n",
    "\n",
    "        while True:\n",
    "            if l_bound == r_bound:\n",
    "                l_bound = 0\n",
    "                r_bound = self.batch_size if self.batch_size < num_img else num_img\n",
    "                \n",
    "                if self.shuffle: np.random.shuffle(self.indices)\n",
    "\n",
    "            # the arrays which hold in the inputs and outputs\n",
    "            x_batch = np.zeros((r_bound - l_bound, self.timesteps, FRAME_H, FRAME_W, 3))\n",
    "            y_batch = np.zeros((r_bound - l_bound, 1))\n",
    "            currt_inst = 0        \n",
    "\n",
    "            for index in self.indices[l_bound:r_bound]:\n",
    "                #if index > 2*self.timesteps:\n",
    "                #    index -= np.random.randint(0, self.timesteps)\n",
    "                \n",
    "                # construct each input\n",
    "                flip = (np.random.random() > 0.5)\n",
    "                bright_factor = 0.5 + np.random.uniform() * 0.5\n",
    "                \n",
    "                for i in xrange(self.timesteps):\n",
    "                    image = cv2.imread(self.file_path + 'images/' + self.images[index-self.timesteps+1+i])\n",
    "                    heigh = image.shape[0]\n",
    "                    image = image[np.concatenate([np.arange(heigh/3), np.arange(heigh*2/3,heigh)]),:,:]\n",
    "                    image = cv2.resize(image.copy(), (FRAME_H, FRAME_W))\n",
    "                    \n",
    "                    if self.jitter: image = augment(image, flip, bright_factor)\n",
    "                    if self.norm:   image = normalize(image)                    \n",
    "                    \n",
    "                    x_batch[currt_inst, i] = image\n",
    "\n",
    "                # construct each output\n",
    "                speeds = [float(speed) for speed in self.labels[index-self.timesteps+1:index+1]]\n",
    "                y_batch[currt_inst] = np.mean(speeds)\n",
    "\n",
    "                currt_inst += 1\n",
    "                \n",
    "            yield x_batch, y_batch\n",
    "\n",
    "            l_bound = r_bound\n",
    "            r_bound = r_bound + self.batch_size\n",
    "            if r_bound > num_img: r_bound = num_img\n",
    "                \n",
    "    def get_size(self):\n",
    "        return len(self.indices)/self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/train/'\n",
    "\n",
    "indices = range(TIMESTEPS-1, len(os.listdir(data_folder + 'images/')), TIMESTEPS)\n",
    "gen_train = BatchGenerator(data_folder, indices, batch_size=4, timesteps=TIMESTEPS)\n",
    "generator = gen_train.get_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(TIMESTEPS, FRAME_H, FRAME_W, 3) # l, h, w, c\n",
    "\n",
    "# 1st layer group\n",
    "model.add(Conv3D(64, (3, 3, 3),  activation='relu', padding='same', name='conv1', input_shape=input_shape))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), padding='valid', name='pool1'))\n",
    "\n",
    "# 2nd layer group\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu', padding='same', name='conv2'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool2'))\n",
    "\n",
    "# 3rd layer group\n",
    "model.add(Conv3D(256, (3, 3, 3), activation='relu', padding='same', name='conv3a'))\n",
    "model.add(Conv3D(256, (3, 3, 3), activation='relu', padding='same', name='conv3b'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool3'))\n",
    "\n",
    "# 4th layer group\n",
    "model.add(Conv3D(512, (3, 3, 3), activation='relu', padding='same', name='conv4a'))\n",
    "model.add(Conv3D(512, (3, 3, 3), activation='relu', padding='same', name='conv4b'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool4'))\n",
    "\n",
    "# 5th layer group\n",
    "model.add(Conv3D(512, (3, 3, 3), activation='relu', padding='same', name='conv5a'))\n",
    "model.add(Conv3D(512, (3, 3, 3), activation='relu', padding='same', name='conv5b'))\n",
    "model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name='zeropad5'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool5'))\n",
    "model.add(Flatten())\n",
    "\n",
    "# FC layers group\n",
    "model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1,    activation='linear', name='fc8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_1m = h5py.File('c3d-sports1M_weights.h5', mode='r')\n",
    "\n",
    "for i in xrange(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    layer_name = 'layer_' + str(i)\n",
    "    \n",
    "    weights = sports_1m[layer_name].values()\n",
    "    weights = [weight.value for weight in weights]\n",
    "    weights = [weight if len(weight.shape) < 4 else weight.transpose(2,3,4,1,0) for weight in weights]\n",
    "    \n",
    "    layer.set_weights(weights)\n",
    "    \n",
    "    # ignore the last 2 layer, 1 dropout and 1 dense\n",
    "    if i > len(model.layers) - 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop  = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=2, mode='min', verbose=1)\n",
    "checkpoint  = ModelCheckpoint('weight_c3d.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "data_folder = 'data/train/'\n",
    "split_ratio = 0.90\n",
    "\n",
    "indices = range(TIMESTEPS-1, len(os.listdir(data_folder + 'images/')), TIMESTEPS)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = list(indices[0:int(len(indices)*split_ratio)])\n",
    "valid_indices = list(indices[int(len(indices)*split_ratio):])\n",
    "\n",
    "gen_train = BatchGenerator(data_folder, train_indices, batch_size=4, timesteps=TIMESTEPS)\n",
    "gen_valid = BatchGenerator(data_folder, valid_indices, batch_size=4, timesteps=TIMESTEPS, jitter = False)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    loss = tf.squared_difference(y_true, y_pred)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_counter  = max([int(num) for num in os.listdir('../logs/speed/')] or [0]) + 1\n",
    "tensorboard = TensorBoard(log_dir='../logs/speed/' + str(tb_counter), histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "sgd = SGD(lr=1e-5, decay=0.0005, momentum=0.9)\n",
    "model.compile(loss=custom_loss, optimizer=sgd)\n",
    "\n",
    "#adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#model.compile(loss=custom_loss, optimizer=adam)\n",
    "\n",
    "#rms = RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#model.compile(loss=custom_loss, optimizer=rms)\n",
    "\n",
    "model.fit_generator(generator = gen_train.get_gen(),\n",
    "                    steps_per_epoch = gen_train.get_size(), \n",
    "                    epochs  = 5, \n",
    "                    verbose = 1,\n",
    "                    validation_data = gen_valid.get_gen(), \n",
    "                    validation_steps = gen_valid.get_size(), \n",
    "                    callbacks = [early_stop, checkpoint, tensorboard], \n",
    "                    max_q_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'udacity' # name without extension of arbitrary dashcam video\n",
    "\n",
    "video_inp = 'data/' + file_name + '.mp4'\n",
    "video_out = 'data/' + file_name + '_out.mp4'\n",
    "label_inp = open('data/' + file_name + '.txt', 'r').readlines() if os.path.exists('data/' + file_name + '.txt') else None\n",
    "label_out = open('data/' + file_name + '_pred.txt', 'w')\n",
    "\n",
    "video_reader = cv2.VideoCapture(video_inp)\n",
    "h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv2.VideoWriter(video_out, fourcc, 20.0, (w, h))\n",
    "\n",
    "x_batch_original = np.zeros((TIMESTEPS, h, w, 3))\n",
    "x_batch = np.zeros((1, TIMESTEPS, FRAME_H, FRAME_W, 3))\n",
    "frame_counter = 0\n",
    "frame_counter_all = 0\n",
    "curr_speed = 0.\n",
    "acc_error = 0\n",
    "\n",
    "while(True):\n",
    "    ret, image = video_reader.read()\n",
    "\n",
    "    if ret == True:\n",
    "        if frame_counter_all > -1: # only start processing from certain frame count\n",
    "            x_batch_original[frame_counter] = image\n",
    "\n",
    "            heigh = image.shape[0]\n",
    "            image = image[np.concatenate([np.arange(heigh/3), np.arange(heigh*2/3,heigh)]),:,:]\n",
    "            image = cv2.resize(image.copy(), (FRAME_H, FRAME_W))\n",
    "            image = normalize(image)\n",
    "\n",
    "            x_batch[0, frame_counter] = image\n",
    "\n",
    "            if frame_counter == TIMESTEPS - 1:\n",
    "                curr_speed = model.predict(x_batch)[0][0]\n",
    "                frame_counter = -1\n",
    "\n",
    "                for i in xrange(TIMESTEPS):\n",
    "                    image = x_batch_original[i]\n",
    "                    caption = 'Speed (Predicted): ' + str(\"{0:.2f}\".format(curr_speed))\n",
    "                    image = cv2.putText(image, caption, (5,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
    "\n",
    "                    # write true speed if available\n",
    "                    if label_inp is not None:\n",
    "                        true_speed = float(label_inp[frame_counter_all-(TIMESTEPS-1)+i].strip())\n",
    "                        caption = 'Speed (Actual): ' + str(\"{0:.2f}\".format(true_speed))\n",
    "                        image = cv2.putText(image, caption, (5,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 3)\n",
    "                        \n",
    "                        acc_error += (curr_speed - true_speed) ** 2\n",
    "                        caption = 'MSE: ' + str(\"{0:.2f}\".format(acc_error/(frame_counter_all-TIMESTEPS+1+i+1)))\n",
    "                        image = cv2.putText(image, caption, (5,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)                        \n",
    "\n",
    "                    video_writer.write(np.uint8(image))\n",
    "                    label_out.write(str(curr_speed) + '\\n')\n",
    "\n",
    "            frame_counter += 1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    frame_counter_all += 1\n",
    "\n",
    "video_reader.release()\n",
    "video_writer.release()\n",
    "\n",
    "label_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_out = 'data/udacity.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv2.VideoWriter(video_out, fourcc, 20.0, (640, 480))\n",
    "\n",
    "labels = open('data/udacity.txt', 'w')\n",
    "\n",
    "with open('data/output/interpolated.csv', 'r') as csvfile:\n",
    "    print csvfile.readline()\n",
    "    \n",
    "    for row in csvfile:\n",
    "        if 'center' in row:\n",
    "            row = row.split(',')\n",
    "\n",
    "            image = cv2.imread('data/output/' + row[5])\n",
    "            \n",
    "            video_writer.write(np.uint8(image))\n",
    "            #labels.write(row[8] + '\\n')\n",
    "            labels.write(str(float(row[8])*0.621371) + '\\n')\n",
    "            \n",
    "video_writer.release()\n",
    "labels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(16, len(os.listdir('data/udacity/images/')), 16)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[0:int(len(indices)*0.8)]\n",
    "valid_indices = indices[int(len(indices)*0.8):]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
